{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlwings as xw\n",
    "import sys\n",
    "\n",
    "# Display entire Scenario string in notebook\n",
    "pd.options.display.max_colwidth = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DSS_extract_models_and_output_tabs_new_DSS(DSS_file_path):\n",
    "    wb = xw.Book(DSS_file_path)\n",
    "    \n",
    "    output_tabs = []\n",
    "    for sheet in wb.sheets:\n",
    "        ws = wb.sheets[sheet]\n",
    "        if ws.range(\"A11\").value == 'Ref: BC Elasticity':\n",
    "            output_tabs.append(sheet.name)\n",
    "                    \n",
    "    model_list = []\n",
    "    for i in range(0,11):\n",
    "        model = wb.sheets['Input'].range(3, 7 + i*6).value\n",
    "        if model == None:\n",
    "            continue\n",
    "        else:\n",
    "            region = str(wb.sheets['Input'].range(4, 7 + i*6).value)\n",
    "            model_id = model + \"_\" + region\n",
    "            model_list.append(model_id)\n",
    "    return model_list, output_tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DSS_extract_models_and_output_tabs_old_DSS(DSS_file_path):\n",
    "    wb = xw.Book(DSS_file_path)\n",
    "    \n",
    "    output_tabs = []\n",
    "    for sheet in wb.sheets:\n",
    "        ws = wb.sheets[sheet]\n",
    "        if ws.range(\"A11\").value == 'Ref: BC Elasticity':\n",
    "            output_tabs.append(sheet.name)\n",
    "                    \n",
    "    model_list = []\n",
    "    for i in range(0,11):\n",
    "        model = str(wb.sheets['Input'].range(3, 8 + i*2).value) \n",
    "        if model == None:\n",
    "            continue\n",
    "        else:\n",
    "            model_year = str(wb.sheets['Input'].range(4, 8 + i*2).value)\n",
    "            region = str(wb.sheets['Input'].range(5, 8 + i*2).value)\n",
    "            model_id = model + \"_\" + model_year + \"_\" + region\n",
    "            model_list.append(model_id)\n",
    "    \n",
    "    return model_list, output_tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_output_tab_new_DSS(DSS_file_path, output_tab, DSS_scenarios):\n",
    "    wb = xw.Book(DSS_file_path)\n",
    "    ws = wb.sheets[output_tab]\n",
    "    \n",
    "    # Reset scenarios to 'x'\n",
    "    for i in range(36,73,2):\n",
    "        ws.range(i,8).value = 'x'\n",
    "    # Write Chooser scenarios    \n",
    "    for index, value in enumerate(DSS_scenarios):\n",
    "        ws.range(36+2*index, 8).value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_output_tab_old_DSS(DSS_file_path, output_tab, DSS_scenarios):\n",
    "    wb = xw.Book(DSS_file_path)\n",
    "    ws = wb.sheets[output_tab]\n",
    "        \n",
    "    #  Reset scenarios to 'x'\n",
    "    for i in range(36,71,2):\n",
    "        ws.range(i,3).value = 'x'\n",
    "    # Write Chooser scenarios    \n",
    "    for index, value in enumerate(DSS_scenarios):\n",
    "        ws.range(34+2*index, 3).value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_spend_filters(df, min_spend, max_spend):\n",
    "    df = df[df['spend_delta'] > min_spend]\n",
    "    df = df[df['spend_delta'] < max_spend]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_DSS_scenarios(single_lever_indices, df, max_no_of_scenarios):\n",
    "    scenarios_row = list(df.index.values)\n",
    "    DSS_scenarios = [x + 1 for x in scenarios_row]\n",
    "    \n",
    "    DSS_scenarios_combined = single_lever_indices\n",
    "    [DSS_scenarios_combined.append(x) for x in DSS_scenarios if x not in single_lever_indices]\n",
    "    \n",
    "    DSS_scenarios_combined = DSS_scenarios_combined[0:max_no_of_scenarios]\n",
    "        \n",
    "    return DSS_scenarios_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_single_lever_indices(df, baseline, delta_columns, APR_delta_columns, min_cash_bool, dbl_min_cash_bool, APR_bool, min_combo_bool, dbl_min_combo_bool, min_lease_bool, dbl_min_lease_bool):\n",
    "\n",
    "    # Find lowest increment of enhancement\n",
    "    cash_min_enh = df[(df['cash_delta'] > 0) & (df['no_of_moves'] == 1)]['cash_delta'].min()\n",
    "    combo_min_enh = df[(df['combo_delta'] > 0) & (df['no_of_moves'] == 1)]['combo_delta'].min()\n",
    "    lease_min_enh = df[(df['lease_delta'] > 0) & (df['no_of_moves'] == 1)]['lease_delta'].min()\n",
    "    \n",
    "    # Create sum across all moves\n",
    "    df['sum_of_moves'] = df[delta_columns[0:8]].sum(axis=1)\n",
    "    \n",
    "    # Find 'combined_APR_delta' that equals -1 move across all terms\n",
    "    APR_single_lever_sum = 0\n",
    "    for x in APR_delta_columns:\n",
    "            if baseline[x] - 0.01 < 0:\n",
    "                APR_single_lever_sum -= baseline[x]\n",
    "            else:\n",
    "                APR_single_lever_sum -= 0.01\n",
    "    \n",
    "    # ID and save single lever moves\n",
    "    for index, row in df.iloc[13:].iterrows():\n",
    "        # Cash single lever move\n",
    "        if (row['cash_delta'] == cash_min_enh) & (row['sum_of_moves'] == cash_min_enh) & (row['no_of_moves'] == 1):\n",
    "            min_cash_single_lever = index\n",
    "        elif (row['cash_delta'] == 2*cash_min_enh) & (row['sum_of_moves'] == 2*cash_min_enh) & (row['no_of_moves'] == 1):\n",
    "            dbl_min_cash_single_lever = index\n",
    "        # APR single lever move\n",
    "        elif (round(row['APR_delta_sum'],3) == APR_single_lever_sum) & (round(row['sum_of_moves'],3) == APR_single_lever_sum) & (row['no_of_moves'] == 1):\n",
    "            APR_single_lever = index\n",
    "        # Combo single lever move\n",
    "        elif (row['combo_delta'] == combo_min_enh) & (row['sum_of_moves'] == combo_min_enh) & (row['no_of_moves'] == 1):\n",
    "            min_combo_single_lever = index\n",
    "        elif (row['combo_delta'] == 2*combo_min_enh) & (row['sum_of_moves'] == 2*combo_min_enh) & (row['no_of_moves'] == 1):\n",
    "            dbl_min_combo_single_lever = index\n",
    "        # Lease single lever move\n",
    "        elif (row['lease_delta'] == lease_min_enh) & (row['sum_of_moves'] == lease_min_enh) & (row['no_of_moves'] == 1):\n",
    "            min_lease_single_lever = index\n",
    "        elif (row['lease_delta'] == 2*lease_min_enh) & (row['sum_of_moves'] == 2*lease_min_enh) & (row['no_of_moves'] == 1):\n",
    "            dbl_min_lease_single_lever = index\n",
    "            \n",
    "    # Add in single lever moves\n",
    "    single_lever_indices = []\n",
    "    if min_cash_bool == True:\n",
    "        try:\n",
    "            single_lever_indices.append(min_cash_single_lever)\n",
    "        except:\n",
    "            next\n",
    "    if dbl_min_cash_bool == True:\n",
    "        try:\n",
    "            single_lever_indices.append(dbl_min_cash_single_lever)\n",
    "        except:\n",
    "            next\n",
    "    if APR_bool == True:\n",
    "        try:\n",
    "            single_lever_indices.append(APR_single_lever)\n",
    "        except:\n",
    "            next\n",
    "    if min_combo_bool == True:\n",
    "        try:\n",
    "            single_lever_indices.append(min_combo_single_lever)\n",
    "        except:\n",
    "            next\n",
    "    if dbl_min_combo_bool == True:\n",
    "        try:\n",
    "            single_lever_indices.append(dbl_min_combo_single_lever)\n",
    "        except:\n",
    "            next\n",
    "    if min_lease_bool == True:\n",
    "        try:\n",
    "            single_lever_indices.append(min_lease_single_lever)\n",
    "        except:\n",
    "            next\n",
    "    if dbl_min_lease_bool == True:\n",
    "        try:\n",
    "            single_lever_indices.append(dbl_min_lease_single_lever)\n",
    "        except:\n",
    "            next  \n",
    "        \n",
    "    single_lever_indices = [x + 1 for x in single_lever_indices]\n",
    "    \n",
    "    return single_lever_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_std(df):\n",
    "    reg_ex = 'std'\n",
    "    reg_ex_filter = df['scenarios'].str.contains(reg_ex)\n",
    "    df = df[~reg_ex_filter]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_CC_APR_diff_amts(df):\n",
    "    CC_APR_nonzero_filter = (df['cash_delta'] != 0) & (df['combo_delta'] != 0)\n",
    "    df['cash_combo_sum'] = round(df['cash_delta']/50.0)*50 + round(df['combo_delta']/50.0)*50\n",
    "    cash_combo_sum_filter = df['cash_combo_sum'] == 0.0\n",
    "    df = df[~(CC_APR_nonzero_filter & cash_combo_sum_filter)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chooser_new_DSS(DSS_file_path, output_tab, model_order, min_cash_bool, dbl_min_cash_bool, APR_bool, min_combo_bool, dbl_min_combo_bool, min_lease_bool, dbl_min_lease_bool, std_bool, CC_combo_bool, min_spend, max_spend, max_no_of_scenarios):\n",
    "    \n",
    "    # Read calc data from Excel\n",
    "    column_headers = ['scenarios','cash_delta','combo_delta','APR_36_delta','APR_48_delta','APR_60_delta','APR_72_delta','APR_84_delta','lease_delta','BC_delta','DC_delta','DFC_delta','DFL_delta','spend_delta','lift_delta','elasticity']\n",
    "    columns_from_excel = 'F,G,I,J,K,L,M,N,T,U,V,X,Z,KU,LE,MK'\n",
    "    delta_columns = ['cash_delta', 'combo_delta', 'APR_delta_sum','lease_delta', 'DC_delta', 'DFC_delta', 'BC_delta', 'DFL_delta', 'spend_delta', 'lift_delta']    \n",
    "    APR_delta_columns = ['APR_36_delta','APR_48_delta','APR_60_delta','APR_72_delta','APR_84_delta']\n",
    "        \n",
    "    df = pd.read_excel(DSS_file_path, sheet_name='Calc', names=column_headers, skiprows=500*(model_order)-1, nrows=500, usecols=columns_from_excel)\n",
    "            \n",
    "    # Remove (#) and spaces at beginning and end of Scenario\n",
    "    df['scenarios'] = df['scenarios'].str.replace('\\\\(.\\\\)','', regex=True).str.lstrip().str.rstrip()\n",
    "\n",
    "    # Remove 'Market' terms\n",
    "    for x in APR_delta_columns:\n",
    "        try: \n",
    "            y = float(baseline[x])\n",
    "        except:\n",
    "            APR_delta_columns.remove(x)\n",
    "            \n",
    "    # Insert 'APR_delta_sum' column\n",
    "    df.insert(8, 'APR_delta_sum', df[APR_delta_columns].sum(axis=1))\n",
    "\n",
    "    # Create no_of_moves column\n",
    "    no_of_moves = 0\n",
    "    df_no_of_moves = []\n",
    "    for index, row in df.iterrows():\n",
    "        no_of_moves = str(row['scenarios']).count('\\n') + 1\n",
    "        df_no_of_moves.append(no_of_moves)\n",
    "    df['no_of_moves'] = df_no_of_moves\n",
    "    \n",
    "    # Set baseline scenario to row 12 in Excel & calculate delta columns\n",
    "    baseline = df.iloc[11]\n",
    "    for x in delta_columns:\n",
    "        df_delta = []\n",
    "        if x == 'lift_delta':\n",
    "            for index, row in df.iterrows():\n",
    "                try:\n",
    "                    delta = row[x]/baseline[x] - 1\n",
    "                    df_delta.append(delta)\n",
    "                except:\n",
    "                    delta = row[x] - baseline[x]\n",
    "                    df_delta.append(delta)\n",
    "        else:\n",
    "            for index, row in df.iterrows():\n",
    "                try:\n",
    "                    delta = row[x] - baseline[x]\n",
    "                    df_delta.append(delta)\n",
    "                except:\n",
    "                    df_delta.append(1000000)\n",
    "        df[x] = df_delta\n",
    "\n",
    "    # Find single lever moves\n",
    "    single_lever_indices = find_single_lever_indices(df, baseline, delta_columns, APR_delta_columns, min_cash_bool, dbl_min_cash_bool, APR_bool, min_combo_bool, dbl_min_combo_bool, min_lease_bool, dbl_min_lease_bool)\n",
    "        \n",
    "    # Filter out NAs, calibration, and duplicate scenarios\n",
    "    df_filtered = df.dropna()\n",
    "    df_filtered = df.iloc[13:]\n",
    "    df_filtered = df_filtered.drop_duplicates(subset=['elasticity','lift_delta','spend_delta'], keep='first')\n",
    "    # Filter out negative cash/finance/BC de-escalating scenarios \n",
    "    df_filtered_copy = df_filtered\n",
    "    for index, row in df_filtered_copy.iterrows():\n",
    "        if (row['cash_delta'] < 0) or (row['combo_delta'] < 0) or (row['BC_delta'] < 0) or (row['DC_delta'] < 0) or (row['DFC_delta'] < 0):\n",
    "            df_filtered.drop(index,inplace=True)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # Find efficient frontier\n",
    "    df_length = df.shape[0]\n",
    "    eff_front = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,df_length,df_length):\n",
    "        for k in range(13,df_length):\n",
    "            current_spend = df['spend_delta'][k + i]\n",
    "            current_lift = df['lift_delta'][k + i]\n",
    "            for j in range(13,df_length):\n",
    "                new_spend = df['spend_delta'][j + i]\n",
    "                new_lift = df['lift_delta'][j + i]\n",
    "                if (new_spend < current_spend) & (new_lift > current_lift):\n",
    "                    break\n",
    "                elif (np.isnan(df['spend_delta'][j + i])) & (j == df_length-1):\n",
    "                    if np.isnan(df['spend_delta'][k + i]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        eff_front = eff_front.append(df.iloc[[k+i]])\n",
    "    # Drop N/As & duplicate scenarios\n",
    "    eff_front = eff_front.dropna()\n",
    "    eff_front = eff_front.drop_duplicates(subset=['scenarios'], keep='first')\n",
    "    \n",
    "    # Create scoring system ranks\n",
    "    \n",
    "    # Elasticity as % of max elasticity from eff_front \n",
    "    df_filtered['elasticity_score'] = abs(df_filtered['elasticity']/eff_front['elasticity'].max())\n",
    "\n",
    "    # Find increment of lowest single lever elasticity\n",
    "    min_single_lever_elast =  df.iloc[6:10]['elasticity'].min()\n",
    "    delta = min_single_lever_elast/eff_front['elasticity'].max()  \n",
    "        \n",
    "    # No. of moves (each additional move = -1 increment)\n",
    "    no_of_moves_dict = {\n",
    "        1: (-delta),\n",
    "        2: (-2*delta),\n",
    "        3: (-3*delta),\n",
    "        4: (-4*delta),\n",
    "        5: (-5*delta),\n",
    "        6: (-6*delta)\n",
    "    }\n",
    "    df_filtered['no_of_moves_score'] = df_filtered['no_of_moves'].map(no_of_moves_dict)\n",
    "\n",
    "    # Eff frontier score (if on frontier = +1 increment) \n",
    "    eff_front_list = []\n",
    "    for index, row in df_filtered.iterrows():\n",
    "        if index in list(eff_front.index):\n",
    "            eff_front_list.append(delta)\n",
    "        else:\n",
    "            eff_front_list.append(0)\n",
    "    df_filtered['eff_front_score'] = eff_front_list\n",
    "\n",
    "    # Total score\n",
    "    df_filtered['total_score'] = df_filtered['elasticity_score'] + df_filtered['no_of_moves_score'] + df_filtered['eff_front_score']\n",
    "    df_filtered.sort_values('total_score', ascending=False, inplace=True)\n",
    "    \n",
    "    # Adjust total_score to punish scenarios too close to scenarios with higher scores\n",
    "    spend_list = []\n",
    "    score_adj_list = []\n",
    "    for index, row in df_filtered.iterrows():\n",
    "        spend_list.append(row['spend_delta'])\n",
    "        spend_score_adj = 0\n",
    "        for spend in spend_list:\n",
    "            if (abs(row['spend_delta'] - spend) >= 50) or (abs(row['spend_delta'] - spend) == 0):\n",
    "                continue\n",
    "            else:\n",
    "                spend_score_adj += abs((50 / (row['spend_delta'] - spend))  * delta)\n",
    "        score_adj_list.append(spend_score_adj)\n",
    "\n",
    "    df_filtered['spend_score_adj'] = score_adj_list\n",
    "    df_filtered['total_score_adj'] = df_filtered['total_score'] - df_filtered['spend_score_adj']\n",
    "\n",
    "    df_filtered.sort_values('total_score_adj', ascending=False, inplace=True)\n",
    "\n",
    "    #Apply remove_std filter\n",
    "    if std_bool == True:\n",
    "        df_filtered = remove_std(df_filtered)\n",
    "    \n",
    "    #Apply Mitsu CC&Combo filter\n",
    "    if CC_combo_bool == True:\n",
    "        df_filtered = remove_CC_APR_diff_amts(df_filtered)\n",
    "    \n",
    "    #Apply spend filters\n",
    "    df_filtered = apply_spend_filters(df_filtered, min_spend, max_spend)\n",
    "    \n",
    "    #Convert to scenario row numbers in Excel\n",
    "    DSS_scenarios = convert_to_DSS_scenarios(single_lever_indices, df_filtered, max_no_of_scenarios)\n",
    "    \n",
    "    #Write to output\n",
    "    write_to_output_tab_new_DSS(DSS_file_path, output_tab, DSS_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chooser_old_DSS(DSS_file_path, output_tab, model_order, min_cash_bool, dbl_min_cash_bool, APR_bool, min_combo_bool, dbl_min_combo_bool, min_lease_bool, dbl_min_lease_bool, std_bool, CC_combo_bool, min_spend, max_spend, max_no_of_scenarios):\n",
    "            \n",
    "    # Read calc data from Excel\n",
    "    column_headers = ['scenarios','cash_delta','DC_delta','DFC_delta','DFL_delta','combo_delta','APR_36_delta','APR_48_delta','APR_60_delta','APR_72_delta','APR_84_delta','lease_delta','BC_delta','spend_delta','lift_delta','elasticity']\n",
    "    columns_from_excel = 'D,E,F,G,H,Q,S,T,U,V,W,Y,Z,JD,JM,KU'\n",
    "    delta_columns = ['cash_delta', 'combo_delta', 'APR_delta_sum','lease_delta', 'DC_delta', 'DFC_delta', 'BC_delta', 'DFL_delta', 'spend_delta', 'lift_delta']    \n",
    "    APR_delta_columns = ['APR_36_delta','APR_48_delta','APR_60_delta','APR_72_delta','APR_84_delta']\n",
    "        \n",
    "    df = pd.read_excel(DSS_file_path, sheet_name='DSS_Calc', names=column_headers, skiprows=100*(model_order)-1, nrows=100, usecols=columns_from_excel)\n",
    "            \n",
    "    # Remove (#) and spaces at beginning and end of Scenario\n",
    "    df['scenarios'] = df['scenarios'].str.replace('\\\\(.\\\\)','', regex=True).str.lstrip().str.rstrip()\n",
    "\n",
    "    # Remove 'Market' terms\n",
    "    for x in APR_delta_columns:\n",
    "        try: \n",
    "            y = float(baseline[x])\n",
    "        except:\n",
    "            APR_delta_columns.remove(x)\n",
    "            \n",
    "    # Insert 'APR_delta_sum' column\n",
    "    df.insert(8, 'APR_delta_sum', df[APR_delta_columns].sum(axis=1))\n",
    "\n",
    "    # Create no_of_moves column\n",
    "    no_of_moves = 0\n",
    "    df_no_of_moves = []\n",
    "    for index, row in df.iterrows():\n",
    "        no_of_moves = str(row['scenarios']).count('\\n') + 1\n",
    "        df_no_of_moves.append(no_of_moves)\n",
    "    df['no_of_moves'] = df_no_of_moves\n",
    "    \n",
    "    # Set baseline scenario to row 2 in Excel & calculate delta columns\n",
    "    baseline = df.iloc[1]\n",
    "    for x in delta_columns:\n",
    "        df_delta = []\n",
    "        if x == 'lift_delta':\n",
    "            for index, row in df.iterrows():\n",
    "                try:\n",
    "                    delta = row[x]/baseline[x] - 1\n",
    "                    df_delta.append(delta)\n",
    "                except:\n",
    "                    delta = row[x] - baseline[x]\n",
    "                    df_delta.append(delta)\n",
    "        else:\n",
    "            for index, row in df.iterrows():\n",
    "                try:\n",
    "                    delta = row[x] - baseline[x]\n",
    "                    df_delta.append(delta)\n",
    "                except:\n",
    "                    df_delta.append(1000000)\n",
    "        df[x] = df_delta\n",
    "\n",
    "    # Find single lever moves\n",
    "    single_lever_indices = find_single_lever_indices(df, baseline, delta_columns, APR_delta_columns, min_cash_bool, dbl_min_cash_bool, APR_bool, min_combo_bool, dbl_min_combo_bool, min_lease_bool, dbl_min_lease_bool)\n",
    "\n",
    "    # Filter out NAs, calibration, and duplicate scenarios\n",
    "    df_filtered = df.dropna()\n",
    "    df_filtered = df.iloc[8:]\n",
    "    df_filtered = df_filtered.drop_duplicates(subset=['elasticity','lift_delta','spend_delta'], keep='first')\n",
    "    # Filter out negative cash/finance/BC de-escalating scenarios \n",
    "    df_filtered_copy = df_filtered\n",
    "    for index, row in df_filtered_copy.iterrows():\n",
    "        if (row['cash_delta'] < 0) or (row['combo_delta'] < 0) or (row['BC_delta'] < 0) or (row['DC_delta'] < 0) or (row['DFC_delta'] < 0):\n",
    "            df_filtered.drop(index,inplace=True)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # Find efficient frontier\n",
    "    df_length = df.shape[0]\n",
    "    eff_front = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,df_length,df_length):\n",
    "        for k in range(8,df_length):\n",
    "            current_spend = df['spend_delta'][k + i]\n",
    "            current_lift = df['lift_delta'][k + i]\n",
    "            for j in range(8,df_length):\n",
    "                new_spend = df['spend_delta'][j + i]\n",
    "                new_lift = df['lift_delta'][j + i]\n",
    "                if (new_spend < current_spend) & (new_lift > current_lift):\n",
    "                    break\n",
    "                elif (np.isnan(df['spend_delta'][j + i])) & (j == df_length-1):\n",
    "                    if np.isnan(df['spend_delta'][k + i]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        eff_front = eff_front.append(df.iloc[[k+i]])\n",
    "    # Drop N/As & duplicate scenarios\n",
    "    eff_front = eff_front.dropna()\n",
    "    eff_front = eff_front.drop_duplicates(subset=['elasticity','lift_delta','spend_delta'], keep='first')\n",
    "    \n",
    "    # Create scoring system ranks\n",
    "    \n",
    "    # Elasticity as % of max elasticity from eff_front \n",
    "    df_filtered['elasticity_score'] = abs(df_filtered['elasticity']/eff_front['elasticity'].max())\n",
    "\n",
    "    # Find increment of lowest single lever elasticity\n",
    "    min_single_lever_elast =  df.iloc[6:10]['elasticity'].min()\n",
    "    delta = min_single_lever_elast/eff_front['elasticity'].max()  \n",
    "        \n",
    "    # No. of moves (each additional move = -1 increment)\n",
    "    no_of_moves_dict = {\n",
    "        1: (-delta),\n",
    "        2: (-2*delta),\n",
    "        3: (-3*delta),\n",
    "        4: (-4*delta),\n",
    "        5: (-5*delta),\n",
    "        6: (-6*delta)\n",
    "    }\n",
    "    df_filtered['no_of_moves_score'] = df_filtered['no_of_moves'].map(no_of_moves_dict)\n",
    "\n",
    "    # Eff frontier score (if on frontier = +1 increment) \n",
    "    eff_front_list = []\n",
    "    for index, row in df_filtered.iterrows():\n",
    "        if index in list(eff_front.index):\n",
    "            eff_front_list.append(delta)\n",
    "        else:\n",
    "            eff_front_list.append(0)\n",
    "    df_filtered['eff_front_score'] = eff_front_list\n",
    "\n",
    "    # Total score\n",
    "    df_filtered['total_score'] = df_filtered['elasticity_score'] + df_filtered['no_of_moves_score'] + df_filtered['eff_front_score']\n",
    "    df_filtered.sort_values('total_score', ascending=False, inplace=True)\n",
    "    \n",
    "    # Adjust total_score to punish scenarios too close to scenarios with higher scores\n",
    "    spend_list = []\n",
    "    score_adj_list = []\n",
    "    for index, row in df_filtered.iterrows():\n",
    "        spend_list.append(row['spend_delta'])\n",
    "        spend_score_adj = 0\n",
    "        for spend in spend_list:\n",
    "            if (abs(row['spend_delta'] - spend) >= 50) or (abs(row['spend_delta'] - spend) == 0):\n",
    "                continue\n",
    "            else:\n",
    "                spend_score_adj += abs((50 / (row['spend_delta'] - spend))  * delta)\n",
    "        score_adj_list.append(spend_score_adj)\n",
    "\n",
    "    df_filtered['spend_score_adj'] = score_adj_list\n",
    "    df_filtered['total_score_adj'] = df_filtered['total_score'] - df_filtered['spend_score_adj']\n",
    "\n",
    "    df_filtered.sort_values('total_score_adj', ascending=False, inplace=True)\n",
    "\n",
    "    #Apply remove_std filter\n",
    "    if std_bool == True:\n",
    "        df_filtered = remove_std(df_filtered)\n",
    "    \n",
    "    #Apply Mitsu CC&Combo filter\n",
    "    if CC_combo_bool == True:\n",
    "        df_filtered = remove_CC_APR_diff_amts(df_filtered)\n",
    "    \n",
    "    #Apply spend filters\n",
    "    df_filtered = apply_spend_filters(df_filtered, min_spend, max_spend)\n",
    "    \n",
    "    #Convert to scenario row numbers in Excel\n",
    "    DSS_scenarios = convert_to_DSS_scenarios(single_lever_indices, df_filtered, max_no_of_scenarios)\n",
    "    \n",
    "    #Write to output\n",
    "    write_to_output_tab_old_DSS(DSS_file_path, output_tab, DSS_scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For later ML use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chosen_scenarios_new_DSS(DSS_file_path, output_tab, df):\n",
    "    #work in progress\n",
    "    \n",
    "    chosen_scenarios = pd.read_excel(DSS_file_path, names=['target_scenarios'], sheet_name=output_tab, usecols='C', skiprows=34, nrows=46)\n",
    "    chosen_scenarios = chosen_scenarios.iloc[::2]\n",
    "    chosen_scenarios = chosen_scenarios.dropna()\n",
    "    chosen_scenarios = chosen_scenarios['target_scenarios'].astype('int')\n",
    "    df['target_scenarios'] = 0\n",
    "    for index, row in chosen_scenarios.iteritems():\n",
    "        df['target_scenarios'].iloc[row-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " def read_chosen_scenarios_old_DSS(DSS_file_path, output_tab, df):   \n",
    "    #work in progress\n",
    "    \n",
    "    chosen_scenarios = pd.read_excel(DSS_file_path, names=['target_scenarios'], sheet_name=output_tab, usecols='C', skiprows=32, nrows=46)\n",
    "    chosen_scenarios = chosen_scenarios.iloc[::2]\n",
    "    chosen_scenarios = chosen_scenarios[~chosen_scenarios.isin(['x'])]\n",
    "    chosen_scenarios = chosen_scenarios.dropna()\n",
    "    chosen_scenarios = chosen_scenarios['target_scenarios'].astype('int')\n",
    "    df['target_scenarios'] = 0\n",
    "    for index, row in chosen_scenarios.iteritems():\n",
    "        df['target_scenarios'].iloc[row-1] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
